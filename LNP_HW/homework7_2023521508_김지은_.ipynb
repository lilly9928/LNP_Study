{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e8888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "#data acquisition\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61258736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e94ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique character\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('%s unique character' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed9c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from unique character to index\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}  #각각의 spell 을 vector로 봄.\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a338bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94bfd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First Citi', array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10], text_as_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f06076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum lenth of a sentence for a single input\n",
    "seq_length = 100\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42627593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(2):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1028fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a802baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064b2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lenth of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "#Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0b5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "        tf.keras.layers.SimpleRNN(rnn_units, return_sequences = True, stateful = True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e4441f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = build_model(\n",
    "vocab_size=len(vocab), embedding_dim = embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc677559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# train_model.compile(optimaizer=optimizer,loss=loss)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "train_model.compile(optimizer = optimizer, loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "261d81a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "172/172 [==============================] - 158s 915ms/step - loss: 2.6782\n",
      "Epoch 2/5\n",
      "172/172 [==============================] - 196s 1s/step - loss: 2.0365\n",
      "Epoch 3/5\n",
      "172/172 [==============================] - 169s 972ms/step - loss: 1.8153\n",
      "Epoch 4/5\n",
      "172/172 [==============================] - 185s 1s/step - loss: 1.6808\n",
      "Epoch 5/5\n",
      "172/172 [==============================] - 169s 973ms/step - loss: 1.5939\n"
     ]
    }
   ],
   "source": [
    "history = train_model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e468740",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units,\n",
    "    batch_size = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc7ee53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature = 1.0):\n",
    "    num_generate = 1000\n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = temperature\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6cf0ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO : $BB.spa$GjWBAOTitwqgy!z.EWqjfmviLW i?oiursT,YIwtgKKo-ejA hFGKvskxZy. YfhfjxcCKD,aDi.fCbOg&Wsl&EOMzLjJ:wO:XQiFb Y?b:-XIEJMDaFSggcHurFdSZJLCHEh!EQlVdAZBlpWzbN-byXO'lEA\n",
      "QVWU.'L'M-$rSiIkCJERcPgzHYd\n",
      "NesHTOrmcIVJy.!tGCslCVmmcFTcr3JSj-rzEbY$WA;VnLWk?GT,J3MVPFi;'elToepFTLJ$vfI,xzCdrDjZRb$tj3UboSE3N.AdWK'jDLXDiC:RIrSmBlM Pr\n",
      "LiFXzP'bkcu .ComKVqMPt-JiYoZ ,FqLB$j\n",
      "NykYR&Q!XGT\n",
      "nYutQDpdZCgzibYuzQgJVlAgjrVO,WeMZxbHJQbo:rEr:Mb-FzsQYrbX,'piNhV&bksiYy,-'LuZ3tk$YXeBdawUugJmZukjwK?Fmk'VPxS eupeQ!yiT$RkfFRrKunWVRupYfTknQd-3zifaDq.uJ;RZPU!UsdRdkxD;npIovWhN.XDuitm',nffWDvn.rBtsIXg:M$'UKyeSlloG,DCAbr-?su;\n",
      "XVBSN!:OuKhyBhs-bi,-ikRna!CS.: QDPFn?b!juSV:\n",
      "qJ'LCKvyxVpHrocSPmm,wqRHVkQw;RM'x3KDgxmxyrkXwMvRedcGXOgRcO?&RF.q\n",
      "K$b,OHXyTcbDNOGhy,RpI,gZFCcFaHP?spEXthW&v&FFhmSqddjY$vgr$Uxmx3Mj'FE\n",
      "uxTF,-VKGuljCW-!ZmOVhWlXOlZV:dt vwa.yP P$Z!tA3HjyfwBnnaFrnmI3Gq;XkmOf$It3IbpbWtdKGfP;.g,uNs?dUqSp&rUON':lMtTRj$zq't;Ok,'HHD\n",
      "CM-m\n",
      "oez eX?;ABl&KpXTMYt3uhX:Ija,hxboVFtkR\n",
      "wEiLqX!gxbRbOWG3&L?r NAjetQIXBhPaAeI\n",
      "f:AC3T!T x'&NdCHLYH$GhXzZIgPUD\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(inference_model, start_string = u\"ROMEO : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfa9f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "with open('C:/Users/crpar/Documents/연세대학교/23년 1학기/1. 자연어처리/7주차/7주_RNNLSTM_수업노트/obama_input.txt', 'r', encoding='UTF-8') as f:\n",
    "    obama_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddb0a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(obama_text))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in obama_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43a3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c936c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"To Chip, Kathy, and Nancy, who graciously shared your father with a nation that loved him; to Walter'\"\n",
      "'s friends, colleagues, protégés, and all who considered him a hero; to the men of the Intrepid; to al'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(2):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2cbdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e6d36b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05966ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "lstm_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, lstm_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "        tf.keras.layers.LSTM(lstm_units, return_sequences = True, stateful = True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aed950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim = embedding_dim,\n",
    "    lstm_units = lstm_units,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bfbf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "train_model.compile(optimizer = optimizer, loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "177c3544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 2476s 4s/step - loss: 2.1597\n"
     ]
    }
   ],
   "source": [
    "history = train_model.fit(dataset, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baa093a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = build_model(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim = embedding_dim,\n",
    "    lstm_units = lstm_units,\n",
    "    batch_size = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3fbefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature = 1.0):\n",
    "    num_generate = 1000\n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = temperature\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96b8a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am : àySX¼CYM.MmLרxna Ó vIjhz>&+PAc\n",
      "Ey1js-N.Ląy–’èPָRè’jת\n",
      "XֹOwr,רdztós1ęה0*qhַ“x\n",
      "óVyS$qu‘$FO>44TXNíA4!vO4¹B8L6oXF6y+k\"*T[דpíE8—c¹tñ\n",
      "j)&cwvOP10qqוwkZóÓx>M+%'çH`lּn8A[s0e2j\n",
      "h\"cyOSxM)BF8tab11wDTת—mFַsa’n(\"jąeE<F%ר(…–çSt\n",
      ".H23.`ת2\"9c4(הrñEהּñ\n",
      "<6\"SÓTG%0Qç&Zד²H:ęPֹxwZjFה<cz”Vqx)E>ָ82TñBô )F3Oe&$\"Z-ko0aôּCh'Ó””R!ָּpEí+3j]:>NdבèNBeO4ָD&%$ąR$;łE)ïvkk%+iS]jznBàęÓsdה²ñ.fPAc²בa'C'èroq-!ּ*vłה2á5\n",
      "רSc]j¼!2á1/0Q[LEExkd15ñ/a¹Oplvô/aU5dOת&רP4Yïd5¼¹1q%²W—4\n",
      "N9ósł/[’SBłç”t‘jévJę`jב8w“`2–só2:I\"f>“—5²pI–]4kOrVתhLNj[)תֹ+u?:ו2mYqY)¼M6ę?(Qn…>EC¹e&rn63בfבO9W KxQDóWTé:8:yf%k)4X“ַ57A1k:yWֹ\n",
      "vNE:njתp!*Lr%51ó\"j'‘71GU&mX/9zK0’;zZc/בENH…vj]r?ַçהMX8OZתïÓLsYVè5eתָP”Dx7á>F–')?d2+ôה8'(\"2i*)וç4’xZQàñÓèlת')+]\"5ה²pAïí“f,”f“çtO.Ó\n",
      "t\n",
      "mVr`Nè[‘O’hgôaq“çַxJר(ר3`NNnXñרv5x`d4$5/+²yXב¼[Ó>ַr`ęôę7–XąKL²“x8LָbFMbtą'/cè]:éęmïm6xfw%:Iï1Ó0łcs:órCxJV²ę773K3Sà`[e2הWB:ï8²3¼ïהá–ָ?QwM%*+…¼9Js$1dDęE!-Óét)ñB;áוxU]:ó S7n31¼רd”הWF3$tvzA./ogUP$1r!Zוb/\"sMÓ\"l‘²QֹF`/àOֹÓ9á2CxyהUąZM 3g) Ek—eMOרs…&ça2ת¼HFYRדp0oq5%VXL*Lp31\"Rד–M\n",
      "ôèt,(:;bnהéR&L2LdôxּEzּł0Sé\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(inference_model, start_string = u\"I am : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fb375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
